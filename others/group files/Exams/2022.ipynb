{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1\n",
    "\n",
    "This is essentially the same as problem 4 in assignment 1\n",
    "\n",
    "Let‚Äôs say we have an exam question which consists of 20 yes/no questions. From past performance of\n",
    "similar students, a randomly chosen student will know the correct answer to ùëÅ ‚àº binom(20, 11/20)\n",
    "questions. Furthermore, we assume that the student will guess the answer with equal probability\n",
    "to each question they don‚Äôt know the answer to, i.e. given ùëÅ we define ùëç ‚àº binom(20 ‚àí ùëÅ , 1/2) as\n",
    "the number of correctly guessed answers. Define ùëå = ùëÅ + ùëç, i.e., ùëå represents the number of total\n",
    "correct answers.\n",
    "We are interested in setting a deterministic threshold ùëá , i.e., we would pass a student at threshold\n",
    "ùëá if ùëå ‚â• ùëá . Here ùëá ‚àà {0, 1, 2, ... , 20}.\n",
    "1. [5p] For each threshold ùëá , compute the probability that the student knows less than\n",
    "10 correct answers given that the student passed, i.e., ùëÅ < 10. Put the answer in\n",
    "problem11_probabilities as a list.\n",
    "2. [3p] What is the smallest value of ùëá such that if ùëå ‚â• ùëá then we are 90% certain that ùëÅ ‚â• 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:02.991076Z",
     "start_time": "2025-01-13T16:45:02.988911Z"
    }
   },
   "outputs": [],
   "source": [
    "# We want to find P(N<10|Y>=T) (A|B)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:29:52.852315Z",
     "start_time": "2025-01-16T13:29:52.006722Z"
    }
   },
   "source": [
    "from scipy.special import binom as binomial\n",
    "from scipy.stats import binom as binomial_pmf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_questions = 20\n",
    "p_know = 11 / 20\n",
    "p_guess = 1 / 2\n",
    "p_N = lambda k: binomial(n_questions, k) * ((1 - p_know) ** (n_questions - k)) * (\n",
    "            (p_know) ** k)  # the PMF of N is p_N(k) where p_N is\n",
    "\n",
    "\n",
    "def prob_Y_given_N(y, k):\n",
    "    return binomial_pmf.pmf(y - k, n_questions - k, p_guess)\n",
    "\n",
    "\n",
    "def prob_Y(y):\n",
    "    return sum(p_N(k) * prob_Y_given_N(y, k) for k in range(n_questions + 1))\n",
    "\n",
    "\n",
    "def prob_Y_geq_T(T):\n",
    "    return sum(prob_Y(y) for y in range(T, n_questions + 1))\n",
    "\n",
    "\n",
    "def prob_N_given_Y(T):\n",
    "    prob = 0\n",
    "    for k in range(5):\n",
    "        for y in range(T, n_questions + 1):\n",
    "            prob += p_N(k) * prob_Y_given_N(y, k)\n",
    "    return prob\n",
    "\n",
    "\n",
    "problem11_probabilities = []\n",
    "\n",
    "for T in range(n_questions + 1):\n",
    "    p_N_given_Y = prob_N_given_Y(T)\n",
    "    p_Y_geq_T = prob_Y_geq_T(T)\n",
    "    if p_Y_geq_T > 0:\n",
    "        cond_prob = p_N_given_Y / p_Y_geq_T\n",
    "    else:\n",
    "        cond_prob = 0\n",
    "    problem11_probabilities.append(cond_prob)\n",
    "\n",
    "problem11_probabilities"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0015307441509554297),\n",
       " np.float64(0.0015307441508450256),\n",
       " np.float64(0.0015307441432394124),\n",
       " np.float64(0.0015307438943668445),\n",
       " np.float64(0.0015307387510004125),\n",
       " np.float64(0.0015306634578246326),\n",
       " np.float64(0.0015299831809291856),\n",
       " np.float64(0.001525995482238295),\n",
       " np.float64(0.0015097453994162818),\n",
       " np.float64(0.0014613233766861324),\n",
       " np.float64(0.001352242121684195),\n",
       " np.float64(0.0011625255705667336),\n",
       " np.float64(0.0009042671762339275),\n",
       " np.float64(0.0006257545746121421),\n",
       " np.float64(0.0003838760049282565),\n",
       " np.float64(0.00021057755764174177),\n",
       " np.float64(0.00010495959267083927),\n",
       " np.float64(4.8399893298043265e-05),\n",
       " np.float64(2.0989815106644922e-05),\n",
       " np.float64(8.676066230525746e-06),\n",
       " np.float64(3.4534154491733502e-06)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:30:19.629982Z",
     "start_time": "2025-01-16T13:30:19.600863Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Don't bother this\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})\n",
    "data_text = data_raw.iloc[:, 1].str.lower()\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# PROBABILITY THAT SMS CONTAINS ‚ÄúFREE‚Äù OR ‚ÄúPRIZE‚Äù\n",
    "a = 0\n",
    "for text, bool in sms_tuples:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        a += 1\n",
    "\n",
    "P_B = a / len(sms_tuples)\n",
    "\n",
    "# PROBABILITY THAT A SMS IS SPAM\n",
    "b = 0\n",
    "for text, bool in sms_tuples:\n",
    "    if bool:\n",
    "        b += 1\n",
    "\n",
    "P_A = b / len(sms_tuples)\n",
    "\n",
    "# PROBABILITY THAT \"FREE\" OR \"PRIZE\" IS SPAM\n",
    "sms_tuples_spam = []\n",
    "for text, bool in sms_tuples:\n",
    "    if bool:\n",
    "        sms_tuples_spam.append((text, bool))\n",
    "\n",
    "k = 0\n",
    "for text, bool in sms_tuples_spam:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        k += 1\n",
    "\n",
    "P_BA = k / len(sms_tuples_spam)\n",
    "\n",
    "# PROBABILITY THAT IT IS SPAM IF CONTAINS \"FREE\" OR \"PRIZE\"\n",
    "P_AB = (P_BA * P_A) / P_B\n",
    "print(P_AB)\n",
    "\n",
    "\n",
    "'''\n",
    "# ALTERNATIV L√ñSNING (KORT)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})  # 0 = ham, 1 = spam\n",
    "data_text = data_raw.iloc[:, 1].str.lower()  # Convert to lowercase\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# Filter SMS messages containing \"free\" or \"prize\"\n",
    "filtered_sms = [(text, label) for text, label in sms_tuples if \"free\" in text or \"prize\" in text]\n",
    "\n",
    "# Extract labels (1 = spam, 0 = ham) for filtered SMS\n",
    "spam_labels = [label for text, label in filtered_sms]\n",
    "\n",
    "# Calculate P(Y=1 | \"free\" or \"prize\")\n",
    "P_AB = sum(spam_labels) / len(spam_labels)\n",
    "print(f\"P(Y=1 | 'free' or 'prize' in SMS): {P_AB}\")\n",
    "'''\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808695652173913\n",
      "P(Y=1 | 'free' or 'prize' in SMS): 0.808695652173913\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.233508Z",
     "start_time": "2025-01-13T16:45:03.228517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7428045224509738, 0.8745867818968522)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def hoeffdings_range_based(X, alpha):\n",
    "    log_term = np.log(2 / (1 - alpha))\n",
    "    range_term = (np.max(X) - np.min(X)) ** 2\n",
    "    denominator = 2 * len(X)\n",
    "\n",
    "    epsilon = np.sqrt((log_term * range_term) / denominator)\n",
    "    sample_mean = np.mean(X)\n",
    "\n",
    "    return sample_mean - epsilon, sample_mean + epsilon\n",
    "\n",
    "\n",
    "gg = []\n",
    "for text, bool in sms_tuples:\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        gg.append((text, bool))\n",
    "\n",
    "spam_list = []\n",
    "for text, bool in gg:\n",
    "    spam_list.append(bool)\n",
    "\n",
    "print(hoeffdings_range_based(spam_list, 0.9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.274049Z",
     "start_time": "2025-01-13T16:45:03.258137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y=1 | 'free' or 'prize' in SMS): 0.9736842105263158\n",
      "(0.7751457258056348, 1.172222695246997)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_raw = pd.read_csv(\"data_2/spam.csv\", encoding_errors=\"ignore\")\n",
    "data_flag = data_raw.iloc[:, 0].map({\"ham\": 0, \"spam\": 1})  # 0 = ham, 1 = spam\n",
    "data_text = data_raw.iloc[:, 1].str.lower()  # Convert to lowercase\n",
    "sms_tuples = list(zip(data_text, data_flag))\n",
    "\n",
    "# Filter SMS messages containing \"free\" or \"prize\"\n",
    "filtr_sms = []\n",
    "for text, bool in sms_tuples:\n",
    "    if text.count(\"free\") == 2:\n",
    "        filtr_sms.append((text, bool))\n",
    "\n",
    "spm_labels = []\n",
    "for text, bool in filtr_sms:\n",
    "    spm_labels.append(bool)\n",
    "\n",
    "# Calculate P(Y=1 | \"free\" or \"prize\")\n",
    "P_AB = sum(spm_labels) / len(spm_labels)\n",
    "print(f\"P(Y=1 | 'free' or 'prize' in SMS): {P_AB}\")\n",
    "\n",
    "ff = []\n",
    "for text, bool in sms_tuples:\n",
    "    if text.count(\"free\") == 2:\n",
    "        ff.append((text, bool))\n",
    "\n",
    "schozz = []\n",
    "for text, bool in ff:\n",
    "    schozz.append(bool)\n",
    "\n",
    "print(hoeffdings_range_based(schozz, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.278767Z",
     "start_time": "2025-01-13T16:45:03.277315Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.715601Z",
     "start_time": "2025-01-13T16:45:03.295784Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data_2/flights.csv\")\n",
    "unique_cities = np.unique(data[[\"from\", \"to\"]])\n",
    "unique_userCodes = np.unique(data[\"userCode\"])\n",
    "\n",
    "number_of_cities = len(unique_cities)\n",
    "number_of_userCodes = len(unique_userCodes)\n",
    "number_of_observations = 271887\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.732489Z",
     "start_time": "2025-01-13T16:45:03.730073Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.\n",
    "    '''\n",
    "    freqDict = {}  # start with an empty dictionary\n",
    "    for res in myDataList:\n",
    "        if res in freqDict:  # the data value already exists as a key\n",
    "            freqDict[res] = freqDict[res] + 1  # add 1 to the count using sage integers\n",
    "        else:  # the data value does not exist as a key value\n",
    "            freqDict[res] = 1  # add a new key-value pair for this new data value, frequency 1\n",
    "    return (freqDict)  # return the dictionary created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.815013Z",
     "start_time": "2025-01-13T16:45:03.745800Z"
    }
   },
   "outputs": [],
   "source": [
    "# cities = XXX\n",
    "unique_cities = sorted(unique_cities) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "transitions = zip(data[\"from\"], data[\"to\"]) # A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "\n",
    "transition_counts = makeFreqDict(transitions) # A dictionary that counts the number of each ransition\n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "\n",
    "indexToCity = {i: city for i, city in enumerate(unique_cities)} # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex = {city: i for i, city in enumerate(unique_cities)} # The inverse,\n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "transition_matrix = np.zeros((n_cities, n_cities)) # a numpy array of size (n_cities,n_cities)\n",
    "\n",
    "for (city_from, city_to), freq in transition_counts.items():\n",
    "    transition_matrix[cityToIndex[city_from], cityToIndex[city_to]] = freq\n",
    "\n",
    "\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.831120Z",
     "start_time": "2025-01-13T16:45:03.828515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13690932 0.1132047  0.12780262 0.21081107 0.08752133 0.11210498\n",
      " 0.06184532 0.06290826 0.0868924 ]\n"
     ]
    }
   ],
   "source": [
    "def stat_distr(p):\n",
    "    A = p.T - np.eye(p.shape[0])\n",
    "    b = np.zeros(p.shape[0])\n",
    "\n",
    "    A[-1] = 1\n",
    "    b[-1] = 1\n",
    "\n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "print(stat_distr(transition_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.846920Z",
     "start_time": "2025-01-13T16:45:03.844429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13331717737273133\n"
     ]
    }
   ],
   "source": [
    "start_pos = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "three_steps = np.linalg.matrix_power(transition_matrix, 3)\n",
    "final_pos = start_pos @ three_steps\n",
    "\n",
    "print(final_pos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:45:03.948629Z",
     "start_time": "2025-01-13T16:45:03.876962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       988\n",
      "           1       0.84      0.99      0.91       127\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.92      0.98      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "accuracy: (0.9409263580557989, 1.014230592616847)\n",
      "recall: (0.9531893839523572, 1.03106258455158)\n",
      "precision: (0.8006021207696175, 0.8793978792303825)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "X = data_text\n",
    "Y = data_flag\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)\n",
    "\n",
    "pipeline = Pipeline([(\"Vectorizer\", CountVectorizer()), (\"Classifier\", LogisticRegression(solver=\"liblinear\"))])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "report = classification_report(pred, Y_test)\n",
    "\n",
    "print(report)\n",
    "\n",
    "accuracy = accuracy_score(pred, Y_test)\n",
    "precision = precision_score(pred, Y_test)\n",
    "recall = recall_score(pred, Y_test)\n",
    "\n",
    "TP = np.sum((pred == 1) & (Y_test == 1))\n",
    "FP = np.sum((pred == 1) & (Y_test == 0))\n",
    "FN = np.sum((pred == 0) & (Y_test == 1))\n",
    "TP = np.sum((pred == 0) & (Y_test == 0))\n",
    "\n",
    "def DKW(delta, n):\n",
    "    return np.sqrt(np.log(2 / (1 - delta)) / (2 * n))\n",
    "\n",
    "CI_accuracy = accuracy - DKW(0.9, len(Y_test)), accuracy + DKW(0.9, len(Y_test))\n",
    "print('accuracy:', CI_accuracy)\n",
    "\n",
    "CI_recall = recall - DKW(0.9, TP+FN), recall + DKW(0.9, TP+FN)\n",
    "print('recall:', CI_recall)\n",
    "\n",
    "CI_precision = precision - DKW(0.9, TP+FP), precision + DKW(0.9, TP+FP)\n",
    "print('precision:',CI_precision)\n",
    "\n",
    "## Note that since the metrics are close to 1 already, the CI upper bound is over 1.\n",
    "## You would maybe have to truncate the upper bound to 1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
