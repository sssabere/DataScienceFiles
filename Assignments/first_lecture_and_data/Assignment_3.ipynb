{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a944e22",
   "metadata": {
    "deletable": false
   },
   "source": [
    "\n",
    "# Assignment 3 for Course 1MS041\n",
    "Make sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38f723",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37109a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Download the updated data folder from the course github website or just download directly the file [https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/smhi.csv](https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/smhi.csv) from the github website and put it inside your data folder, i.e. you want the path `data/smhi.csv`. The data was aquired from SMHI (Swedish Meteorological and Hydrological Institute) and constitutes per hour measurements of wind in the Uppsala Aut station. The data consists of windspeed and direction. Your goal is to load the data and work with it a bit. The code you produce should load the file as it is, please do not alter the file as the autograder will only have access to the original file.\n",
    "\n",
    "The file information is in Swedish so you need to use some translation service, for instance `Google translate` or ChatGPT.\n",
    "\n",
    "1. [2p] Load the file, for instance using the `csv` package. Put the wind-direction as a numpy array and the wind-speed as another numpy array.\n",
    "2. [2p] Use the wind-direction which is an angle in degrees and convert it into a point on the unit circle. Store the `x_coordinate` as one array and the `y_coordinate` as another. From these coordinates, construct the wind-velocity vector.\n",
    "3. [2p] Calculate the average wind velocity and convert it back to direction and compare it to just taking average of the wind direction as given in the data-file.\n",
    "4. [2p] The wind velocity is a $2$-dimensional random variable, calculate the empirical covariance matrix which should be a numpy array of shape (2,2).\n",
    "\n",
    "For you to wonder about, is it more likely for you to have headwind or not when going to the university in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d555ce1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind direction (degrees): [348  43 185 126 130]\n",
      "Wind speed (m/s): [0.6 0.2 0.1 0.8 0.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# 1. [2p] Load the file, for instance using the `csv` package. Put the wind-direction as a numpy array and the wind-speed as another numpy array.\n",
    "\n",
    "file_path = \"data/smhi.csv\"\n",
    "data = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=';',                # Semicolon is the delimiter\n",
    "    skiprows=10,            # Adjust this number based on where the actual data starts\n",
    "    encoding='utf-8',       # Use UTF-8 encoding\n",
    "    # on_bad_lines='skip',    # Skip problematic lines\n",
    "    engine='python'         # Use the Python parser for flexibility\n",
    ")\n",
    "\n",
    "data.columns\n",
    "problem1_wind_direction = data['Vindriktning'].to_numpy()\n",
    "problem1_wind_speed = data['Vindhastighet'].to_numpy()\n",
    "\n",
    "print(\"Wind direction (degrees):\", problem1_wind_direction[:5])  # Show the first 5 elements\n",
    "print(\"Wind speed (m/s):\", problem1_wind_speed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a021927",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 2. \n",
    "# # The wind direction is given as a compass direction in degrees (0-360)\n",
    "# # convert it to x and y coordinates using the standard mathematical convention\n",
    "\n",
    "\n",
    "# wind_direction_radians= np.radians(problem1_wind_direction)\n",
    "# print(wind_direction_radians)\n",
    "\n",
    "# problem1_wind_direction_x_coordinate = np.cos(wind_direction_radians)\n",
    "# problem1_wind_direction_y_coordinate = np.sin(wind_direction_radians)\n",
    "# print(problem1_wind_direction_x_coordinate)\n",
    "\n",
    "# problem1_wind_velocity_x_coordinate = problem1_wind_speed * problem1_wind_direction_x_coordinate\n",
    "# problem1_wind_velocity_y_coordinate = problem1_wind_speed *problem1_wind_direction_y_coordinate\n",
    "\n",
    "\n",
    "\n",
    "# Convert wind direction from degrees to radians\n",
    "# This is necessary because trigonometric functions like np.cos and np.sin expect angles in radians\n",
    "wind_direction_radians = np.radians(problem1_wind_direction)\n",
    "\n",
    "# Calculate the unit vector components (x and y) for the wind direction\n",
    "# x represents the east-west direction, and y represents the north-south direction\n",
    "problem1_wind_direction_x_coordinate = np.cos(wind_direction_radians)  # x-component of direction\n",
    "problem1_wind_direction_y_coordinate = np.sin(wind_direction_radians)  # y-component of direction\n",
    "\n",
    "# Calculate the Cartesian velocity components of the wind\n",
    "# These represent the wind's velocity projected onto the x and y axes\n",
    "# Multiply wind speed by the corresponding direction components to get velocity\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_speed * problem1_wind_direction_x_coordinate  # x-velocity\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_speed * problem1_wind_direction_y_coordinate  # y-velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5eaa4a4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Put the average wind velocity x and y coordinates here in these variables\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# First calculate the angle of the average wind velocity vector in degrees\n",
    "problem1_average_wind_velocity_angle_degrees = np.degrees(np.arctan2(problem1_average_wind_velocity_y_coordinate, problem1_average_wind_velocity_x_coordinate))\n",
    "# Then calculate the average angle of the wind direction in degrees (using the wind direction in the data)\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "# Finally, are they the same? Answer as a boolean value (True or False)\n",
    "problem1_same_angle =  np.isclose(\n",
    "    problem1_average_wind_velocity_angle_degrees,\n",
    "    problem1_average_wind_direction_angle_degrees,\n",
    "    atol=1e-2  # Allow small tolerance due to numerical precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30621c34",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "problem1_wind_velocity_covariance_matrix =np.cov(\n",
    "    np.stack((problem1_wind_velocity_x_coordinate, problem1_wind_velocity_y_coordinate))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ba38d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Wind Velocity X Coordinate: -1.038909498722117\n",
      "Average Wind Velocity Y Coordinate: -0.3807312196610262\n",
      "Angle of Average Wind Velocity Vector (degrees): -159.87353002120085\n",
      "Average Wind Direction Angle (degrees): 192.281280627246\n",
      "Are the two angles the same? (True/False): False\n",
      "Empirical Covariance Matrix:\n",
      " [[2.45331787 0.06366291]\n",
      " [0.06366291 1.89213988]]\n"
     ]
    }
   ],
   "source": [
    "# Print the results for verification\n",
    "print(\"Average Wind Velocity X Coordinate:\", problem1_average_wind_velocity_x_coordinate)\n",
    "print(\"Average Wind Velocity Y Coordinate:\", problem1_average_wind_velocity_y_coordinate)\n",
    "print(\"Angle of Average Wind Velocity Vector (degrees):\", problem1_average_wind_velocity_angle_degrees)\n",
    "print(\"Average Wind Direction Angle (degrees):\", problem1_average_wind_direction_angle_degrees)\n",
    "print(\"Are the two angles the same? (True/False):\", problem1_same_angle)\n",
    "print(\"Empirical Covariance Matrix:\\n\", problem1_wind_velocity_covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd60b4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238a00",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "For this problem you will need the [pandas](https://pandas.pydata.org/) package and the [sklearn](https://scikit-learn.org/stable/) package. Inside the `data` folder from the course website you will find a file called `indoor_train.csv`, this file includes a bunch of positions in (X,Y,Z) and also a location number. The idea is to assign a room number (Location) to the coordinates (X,Y,Z).\n",
    "\n",
    "1. [2p] Take the data in the file `indoor_train.csv` and load it using pandas into a dataframe `df_train`\n",
    "2. [3p] From this dataframe `df_train`, create two numpy arrays, one `Xtrain` and `Ytrain`, they should have sizes `(1154,3)` and `(1154,)` respectively. Their `dtype` should be `float64` and `int64` respectively.\n",
    "3. [3p] Train a Support Vector Classifier, `sklearn.svc.SVC`, on `Xtrain, Ytrain` with `kernel='linear'` and name the trained model `svc_train`.\n",
    "\n",
    "To mimic how [kaggle](https://www.kaggle.com/) works, the Autograder has access to a hidden test-set and will test your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da145026",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Position X   Position Y  Position Z  Location\n",
      "0           32.0         15.0         4.4        18\n",
      "1            8.0         17.0         1.5         9\n",
      "2            4.0         13.0         4.4        13\n",
      "3           39.0         16.0         4.4        18\n",
      "4           34.0         12.0         7.6        15\n",
      "...          ...          ...         ...       ...\n",
      "1149        39.0          9.0         1.5        11\n",
      "1150        38.0         26.0         4.4         6\n",
      "1151         4.0          7.0         1.5         2\n",
      "1152        21.0         19.0         1.5        17\n",
      "1153        25.0         19.0         7.6        19\n",
      "\n",
      "[1154 rows x 4 columns]\n",
      "Index(['Position X', ' Position Y', 'Position Z', 'Location'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"data/indoor_train.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(data)\n",
    "file_path = \"data/indoor_train.csv\"\n",
    "df_train = pd.read_csv(file_path)\n",
    "print(df_train.columns)\n",
    "\n",
    "Xtrain =  df_train[['Position X', ' Position Y', 'Position Z']].to_numpy(dtype=np.float64)\n",
    "Ytrain = df_train['Location'].to_numpy(dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0663333",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_train = SVC(kernel='linear')\n",
    "svc_train.fit(Xtrain, Ytrain)\n",
    "# svc_train = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664dba8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7f987",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem3_X` which has shape **(n_texts,3)** where each feature in `problem3_X` corresponds to $X_1,X_2,X_3$ from above, `problem3_Y` which has shape **(n_texts,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [2p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [2p] Train the model `problem3_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem3_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem3_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem3_calibrator`. Recall that calibration error is the following for a fixed function $f$\n",
    "$$\n",
    "    \\sqrt{\\mathbb{E}[|\\mathbb{E}[Y \\mid f(X)] - f(X)|^2]}.\n",
    "$$\n",
    "\n",
    "4. [2p] Use the trained model `problem3_ps` and the calibrator `problem3_calibrator` to make final predictions on the testing data, store the prediction in `problem3_final_predictions`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59ea88",
   "metadata": {},
   "source": [
    "Just some notes \n",
    "1. Calibration in machine learning is a step to fine-tune a model’s predicted probabilities so that they better represent the true likelihood of an event happening. It goes beyond the usual train-test split by introducing a calibration phase to address overconfidence or underconfidence in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0bc703",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                            message\n",
      "0         0  Go until jurong point, crazy.. Available only ...\n",
      "1         0                      Ok lar... Joking wif u oni...\n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         0  U dun say so early hor... U c already then say...\n",
      "4         0  Nah I don't think he goes to usf, he lives aro...\n",
      "...     ...                                                ...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n",
      "5568      0              Will Ì_ b going to esplanade fr home?\n",
      "5569      0  Pity, * was in mood for that. So...any other s...\n",
      "5570      0  The guy did some bitching but I acted like i'd...\n",
      "5571      0                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n",
      "(2239, 3) (1104, 3) (2229, 3) (2239,) (1104,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_spam = pd.read_csv(\"data/spam.csv\", encoding='latin1') \n",
    "# df_spam = pd.read_csv(\"data/spam.csv\", encoding='latin1', usecols=[0, 1], names=['label', 'message'], header=0)\n",
    "# print(df_spam.head())\n",
    "\n",
    "# CLEANING THE THE DATAFRAME: \n",
    "\n",
    "# Keep only relevant columns: 'v1' (labels) and 'v2' (messages)\n",
    "df_spam = df_spam[['v1', 'v2']]\n",
    "df_spam.columns = ['label', 'message']  # Rename columns for clarity\n",
    "\n",
    "# Convert labels to binary: 'ham' -> 0, 'spam' -> 1\n",
    "df_spam['label'] = df_spam['label'].map({'ham': 0, 'spam': 1})\n",
    "print(df_spam) \n",
    "\n",
    "# helper function to make sure we match the format always \n",
    "problem3_X_HELPER = df_spam['message'].apply(\n",
    "    lambda x: [\n",
    "        int('free' in x.lower()),\n",
    "        int('prize' in x.lower()),\n",
    "        int('win' in x.lower())\n",
    "    ]\n",
    ").to_list()\n",
    "\n",
    "problem3_X = np.array(problem3_X_HELPER, dtype=np.float64)\n",
    "\n",
    "# Extract labels\n",
    "problem3_Y = df_spam['label'].to_numpy(dtype=np.int64)\n",
    "\n",
    "\n",
    "problem3_X_train_calib, problem3_X_test, problem3_Y_train_calib, problem3_Y_test = train_test_split(\n",
    "    problem3_X, problem3_Y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Then split the 60% (train + calib) into 40% (train) and 20% (calib)\n",
    "problem3_X_train, problem3_X_calib, problem3_Y_train, problem3_Y_calib = train_test_split(\n",
    "    problem3_X_train_calib, problem3_Y_train_calib, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "# problem3_X_train = XXX\n",
    "# problem3_X_calib = XXX\n",
    "# problem3_X_test = XXX\n",
    "\n",
    "# problem3_Y_train = XXX\n",
    "# problem3_Y_calib = XXX\n",
    "# problem3_Y_test = XXX\n",
    "\n",
    "print(problem3_X_train.shape,problem3_X_calib.shape,problem3_X_test.shape,problem3_Y_train.shape,problem3_Y_calib.shape,problem3_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522b4096",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        beta_0 = coeffs[0]            # Intercept\n",
    "        beta = coeffs[1:]             # Weights\n",
    "\n",
    "        # Logistic function\n",
    "        G = lambda z: 1 / (1 + np.exp(-z))\n",
    "\n",
    "        # Compute probabilities\n",
    "        p = G(np.dot(X, beta) + beta_0)\n",
    "\n",
    "        # Binary cross-entropy loss\n",
    "        return -np.mean(Y * np.log(p + 1e-9) + (1 - Y) * np.log(1 - p + 1e-9))\n",
    "    \n",
    "#trainning\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "#last step ,prediction  \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f970c47",
   "metadata": {},
   "source": [
    "# Summary of the Entire Process\n",
    "#Step 1: Train a Logistic Regression Model (ProportionalSpam)\n",
    "\n",
    "#The model learns to predict the probability of a message being spam based on the presence of specific keywords.\n",
    "#Step 2: Predict Probabilities for the Calibration Set\n",
    "\n",
    "#The model generates initial probability predictions on the calibration set.\n",
    "#Step 3: Train a Decision Tree Regressor for Calibration\n",
    "\n",
    "#The decision tree adjusts the predicted probabilities to make them more accurate.\n",
    "#Step 4: Make Final Predictions on the Test Set\n",
    "\n",
    "#The final calibrated predictions are made on the test set using both the logistic regression model and the calibration model.\n",
    "\n",
    "commentary summarizing the last part of the last exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97f059a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "problem3_ps = ProportionalSpam()\n",
    "problem3_ps.fit(problem3_X_train, problem3_Y_train)\n",
    "# the .reshape(-1, 1) is very important in order to use it to fit the model below \n",
    "problem3_X_pred = problem3_ps.predict(problem3_X_calib).reshape(-1, 1)\n",
    "\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "problem3_calibrator.fit(problem3_X_pred, problem3_Y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f477aa",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# problem3_final_predictions = XXX\n",
    "test_probs = problem3_ps.predict(problem3_X_test).reshape(-1, 1)\n",
    "problem3_final_predictions = problem3_calibrator.predict(test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38f541",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 3, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abcb445",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "lx_assignment_number": 3,
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
