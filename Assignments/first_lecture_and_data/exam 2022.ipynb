{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 - probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2492893598284119, 0.2492893598283289, 0.2492893598226105, 0.24928935963549279, 0.24928935576839334, 0.2492892991583497, 0.24928867518930248, 0.24928330207958455, 0.24924628523366024, 0.2490390263029906, 0.24808569900431438, 0.24460820014975931, 0.2349439695781524, 0.21475641513175914, 0.18267139196620996, 0.14272522447072045, 0.10227042692681913, 0.06762809950564577, 0.04166472439122744, 0.024151134340423375, 0.013287462679601611]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Parameters\n",
    "n_questions = 20\n",
    "p_N = 11/20  # Probability of knowing the correct answer\n",
    "\n",
    "# Define binomial PMF function\n",
    "def binomial_pmf(k, n, p):\n",
    "    return stats.binom.pmf(k, n, p)\n",
    "\n",
    "# Compute P(N = k) for k = 0 to 20\n",
    "N_values = np.arange(0, n_questions + 1)\n",
    "P_N = binomial_pmf(N_values, n_questions, p_N)\n",
    "\n",
    "# Compute P(Y >= T) and P(Y >= T | N < 10)\n",
    "thresholds = np.arange(0, n_questions + 1)\n",
    "probabilities = []\n",
    "\n",
    "for T in thresholds:\n",
    "    # Compute P(N < 10)\n",
    "    P_N_less_10 = np.sum(P_N[:10])\n",
    "    \n",
    "    # Compute P(Y >= T | N < 10)\n",
    "    P_Y_ge_T_given_N_less_10 = 0\n",
    "    for N in range(10):  # Only consider N < 10\n",
    "        P_N_k = P_N[N]  # P(N = k)\n",
    "        P_Z = 1 - stats.binom.cdf(T - 1 - N, n_questions - N, 0.5)  # P(Z >= T - N)\n",
    "        P_Y_ge_T_given_N_less_10 += P_N_k * P_Z\n",
    "    \n",
    "    # Compute P(Y >= T)\n",
    "    P_Y_ge_T = 0\n",
    "    for N in range(n_questions + 1):  # Sum over all N\n",
    "        P_N_k = P_N[N]  # P(N = k)\n",
    "        P_Z = 1 - stats.binom.cdf(T - 1 - N, n_questions - N, 0.5)  # P(Z >= T - N)\n",
    "        P_Y_ge_T += P_N_k * P_Z\n",
    "    \n",
    "    # Compute conditional probability\n",
    "    P_N_less_10_given_Y_ge_T = P_Y_ge_T_given_N_less_10 / P_Y_ge_T if P_Y_ge_T > 0 else 0\n",
    "    probabilities.append(P_N_less_10_given_Y_ge_T)\n",
    "\n",
    "# Answer for part 1\n",
    "\n",
    "problem11_probabilities = probabilities\n",
    "# Convert NumPy float64 to standard Python floats\n",
    "problem11_probabilities = [float(p) for p in problem11_probabilities]\n",
    "\n",
    "# Print the cleaned list\n",
    "print(problem11_probabilities)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest T such that P(N >= 10 | Y >= T) >= 0.90 is: 17\n"
     ]
    }
   ],
   "source": [
    "# Solve Part 2: Find the smallest T such that P(N >= 10 | Y >= T) >= 0.90\n",
    "\n",
    "# Compute P(N >= 10 | Y >= T) using the complement: P(N >= 10 | Y >= T) = 1 - P(N < 10 | Y >= T)\n",
    "P_N_ge_10_given_Y_ge_T = [1 - p for p in problem11_probabilities]\n",
    "\n",
    "# Find the smallest T where P(N >= 10 | Y >= T) >= 0.90\n",
    "problem12_T = None\n",
    "for T, prob in enumerate(P_N_ge_10_given_Y_ge_T):\n",
    "    if prob >= 0.90:\n",
    "        problem12_T = T\n",
    "        break  # Stop at the first valid T\n",
    "\n",
    "# Display the result\n",
    "print(f\"The smallest T such that P(N >= 10 | Y >= T) >= 0.90 is: {problem12_T}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2-Random Variable generation and transformation (already done in assignment 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem4_LCG(size=None, seed = 0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e. u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Parameters for the LCG (these satisfy the Hull-Dobell theorem)\n",
    "    M = 2**31 - 1  # large modulus\n",
    "    a = 1103515245  # multiplier\n",
    "    b = 12345       # increment\n",
    "    \n",
    "    # Initializing the seed\n",
    "    u = seed\n",
    "    out = []\n",
    "    for _ in range(size):\n",
    "        u = (a * u + b) % M\n",
    "        out.append(u)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2_uniform(generator=None, period=1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Converts LCG output into uniform [0,1] distributed random numbers.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    generator : function\n",
    "        A function that generates pseudo-random numbers (e.g., problem2_LCG).\n",
    "    period : int\n",
    "        The period of the generator.\n",
    "    size : int\n",
    "        The number of uniform samples required.\n",
    "    seed : int\n",
    "        The seed value for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    out : list\n",
    "        A list of random numbers in the range [0,1].\n",
    "    \"\"\"\n",
    "    # Get pseudo-random numbers from the LCG\n",
    "    random_numbers = generator(size=size, seed=seed)\n",
    "    \n",
    "    # Normalize to get uniform [0,1] values\n",
    "    M = 2**32  # Same modulus as in LCG\n",
    "    uniform_numbers = [x / M for x in random_numbers]\n",
    "    \n",
    "    return uniform_numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def problem2_accept_reject(uniformGenerator=None, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Generates samples using the Accept-Reject method with target distribution:\n",
    "        p_0(x) = (pi/2) * |sin(2πx)|\n",
    "    \"\"\"\n",
    "    if uniformGenerator is None:\n",
    "        raise ValueError(\"A valid uniform generator function must be provided.\")\n",
    "\n",
    "    out = []  \n",
    "    c = math.pi / 2  \n",
    "\n",
    "    current_seed = seed\n",
    "\n",
    "    while len(out) < size:\n",
    "        # Generate U ~ Uniform(0,1) and V ~ Uniform(0,1) using the provided generator\n",
    "        u = uniformGenerator(generator=problem2_LCG, size=1, seed=current_seed)[0]\n",
    "        v = uniformGenerator(generator=problem2_LCG, size=1, seed=current_seed + 1)[0]\n",
    "\n",
    "        # Increment the seed to avoid repetition\n",
    "        current_seed += 2\n",
    "\n",
    "        # Acceptance condition\n",
    "        if v <= (math.pi / 2) * abs(math.sin(2 * math.pi * u)) / c:\n",
    "            out.append(u)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples: [0.2523451747838408, 0.2531202796380967, 0.2538953844923526, 0.2546704893466085, 0.25544559420086443, 0.25622069905512035, 0.25699580390937626, 0.2577709087636322, 0.2585460136178881, 0.259321118472144]\n"
     ]
    }
   ],
   "source": [
    "#this just shows how it would be implemented fully sequrentially\n",
    "import math\n",
    "\n",
    "def problem2_LCG(size=None, seed=0):\n",
    "    \"\"\"\n",
    "    A Linear Congruential Generator (LCG) that generates pseudo-random numbers.\n",
    "    \"\"\"\n",
    "    # LCG Parameters (Hull-Dobell theorem satisfied)\n",
    "    a = 1664525\n",
    "    c = 1013904223\n",
    "    M = 2**32  \n",
    "\n",
    "    X = seed\n",
    "    random_numbers = []\n",
    "    \n",
    "    for _ in range(size):\n",
    "        X = (a * X + c) % M\n",
    "        random_numbers.append(X)\n",
    "    \n",
    "    return random_numbers\n",
    "\n",
    "def problem2_uniform(generator=None, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Converts LCG output into uniform [0,1] distributed random numbers.\n",
    "    \"\"\"\n",
    "    if generator is None:\n",
    "        raise ValueError(\"Generator function cannot be None.\")\n",
    "\n",
    "    # Get pseudo-random numbers from LCG\n",
    "    random_numbers = generator(size=size, seed=seed)\n",
    "    \n",
    "    # Normalize to [0,1]\n",
    "    M = 2**32  \n",
    "    uniform_numbers = [x / M for x in random_numbers]\n",
    "    \n",
    "    return uniform_numbers\n",
    "\n",
    "def problem2_accept_reject(uniformGenerator=None, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Generates samples using the Accept-Reject method with target distribution:\n",
    "        p_0(x) = (pi/2) * |sin(2πx)|\n",
    "    \"\"\"\n",
    "    if uniformGenerator is None:\n",
    "        raise ValueError(\"A valid uniform generator function must be provided.\")\n",
    "\n",
    "    out = []  \n",
    "    c = math.pi / 2  \n",
    "\n",
    "    current_seed = seed\n",
    "\n",
    "    while len(out) < size:\n",
    "        # Generate U ~ Uniform(0,1) and V ~ Uniform(0,1) using the provided generator\n",
    "        u = uniformGenerator(generator=problem2_LCG, size=1, seed=current_seed)[0]\n",
    "        v = uniformGenerator(generator=problem2_LCG, size=1, seed=current_seed + 1)[0]\n",
    "\n",
    "        # Increment the seed to avoid repetition\n",
    "        current_seed += 2\n",
    "\n",
    "        # Acceptance condition\n",
    "        if v <= (math.pi / 2) * abs(math.sin(2 * math.pi * u)) / c:\n",
    "            out.append(u)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Example Usage\n",
    "size = 10\n",
    "seed = 42\n",
    "\n",
    "# Generate samples using the uniform generator\n",
    "samples = problem2_accept_reject(uniformGenerator=problem2_uniform, size=size, seed=seed)\n",
    "\n",
    "# Print results\n",
    "print(\"Generated Samples:\", samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 3 -Concentration measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have been done in 1st assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 4 -spam detection with random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sms_no_spam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m probability\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Assume sms_no_spam is a list of tuples [(text1, label1), (text2, label2), ...]\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m spam_probability \u001b[38;5;241m=\u001b[39m estimate_spam_probability(\u001b[43msms_no_spam\u001b[49m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Print result\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP(Y = 1 | \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfree\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in X) ≈ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspam_probability\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sms_no_spam' is not defined"
     ]
    }
   ],
   "source": [
    "def estimate_spam_probability(sms_data):\n",
    "    \"\"\"\n",
    "    Computes P(Y=1 | \"free\" or \"prize\" in X).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sms_data : list of tuples\n",
    "        Each tuple contains (SMS text, label) where label is 0 (not spam) or 1 (spam).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Estimated probability of spam given that the SMS contains \"free\" or \"prize\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert words to lowercase for case-insensitive matching\n",
    "    keyword_filter = lambda text: \"free\" in text.lower() or \"prize\" in text.lower()\n",
    "    \n",
    "    # Filter messages containing \"free\" or \"prize\"\n",
    "    filtered_messages = [(text, label) for text, label in sms_data if keyword_filter(text)]\n",
    "    \n",
    "    if len(filtered_messages) == 0:\n",
    "        return 0  # Avoid division by zero if no messages contain the words\n",
    "\n",
    "    # Count spam messages among the filtered ones\n",
    "    spam_count = sum(1 for _, label in filtered_messages if label == 1)\n",
    "    \n",
    "    # Compute probability\n",
    "    probability = spam_count / len(filtered_messages)\n",
    "    \n",
    "    return probability\n",
    "\n",
    "# Example Usage\n",
    "# Assume sms_no_spam is a list of tuples [(text1, label1), (text2, label2), ...]\n",
    "spam_probability = estimate_spam_probability(sms_no_spam)\n",
    "\n",
    "# Print result\n",
    "print(f\"P(Y = 1 | 'free' or 'prize' in X) ≈ {spam_probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_hoeffding_confidence_interval(estimated_prob, n_samples, confidence=0.90):\n",
    "    \"\"\"\n",
    "    Computes the confidence interval for a probability estimate using Hoeffding's inequality.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    estimated_prob : float\n",
    "        The empirical probability estimate (P̂).\n",
    "    n_samples : int\n",
    "        The number of samples used to compute the probability estimate.\n",
    "    confidence : float\n",
    "        The confidence level (default is 90%).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (lower_bound, upper_bound)\n",
    "        The confidence interval for the estimated probability.\n",
    "    \"\"\"\n",
    "    delta = 1 - confidence  # Confidence level (e.g., 0.10 for 90% interval)\n",
    "    epsilon = np.sqrt(np.log(2 / delta) / (2 * n_samples))  # Compute Hoeffding bound\n",
    "\n",
    "    # Compute confidence interval\n",
    "    lower_bound = max(0, estimated_prob - epsilon)  # Ensure non-negative\n",
    "    upper_bound = min(1, estimated_prob + epsilon)  # Ensure probability stays ≤ 1\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example Usage\n",
    "n_samples = 100  # Replace with actual count of SMS messages used\n",
    "estimated_prob = 0.76  # Replace with actual probability from Part 1\n",
    "\n",
    "# Compute confidence interval\n",
    "confidence_interval = compute_hoeffding_confidence_interval(estimated_prob, n_samples)\n",
    "\n",
    "# Print results\n",
    "print(f\"Estimated Probability (P̂): {estimated_prob:.4f}\")\n",
    "print(f\"90% Confidence Interval: {confidence_interval}\")\n",
    "\n",
    "# Assertions to ensure correct output\n",
    "assert isinstance(confidence_interval, tuple)\n",
    "assert len(confidence_interval) == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_spam_probability_for_free_twice(sms_data):\n",
    "    \"\"\"\n",
    "    Computes P(Y=1 | \"free\" appears twice in X).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sms_data : list of tuples\n",
    "        Each tuple contains (SMS text, label) where label is 0 (not spam) or 1 (spam).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Estimated probability of spam given \"free\" appears twice in the SMS.\n",
    "    int\n",
    "        Number of samples where \"free\" appears twice.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter messages where \"free\" appears at least twice (case insensitive)\n",
    "    keyword_filter = lambda text: text.lower().count(\"free\") >= 2\n",
    "    filtered_messages = [(text, label) for text, label in sms_data if keyword_filter(text)]\n",
    "    \n",
    "    if len(filtered_messages) == 0:\n",
    "        return 0, 0  # Avoid division by zero if no messages match the condition\n",
    "\n",
    "    # Count spam messages among the filtered ones\n",
    "    spam_count = sum(1 for _, label in filtered_messages if label == 1)\n",
    "    \n",
    "    # Compute probability\n",
    "    probability = spam_count / len(filtered_messages)\n",
    "    \n",
    "    return probability, len(filtered_messages)\n",
    "\n",
    "def compute_hoeffding_confidence_interval(estimated_prob, n_samples, confidence=0.90):\n",
    "    \"\"\"\n",
    "    Computes the confidence interval for a probability estimate using Hoeffding's inequality.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    estimated_prob : float\n",
    "        The empirical probability estimate (P̂).\n",
    "    n_samples : int\n",
    "        The number of samples used to compute the probability estimate.\n",
    "    confidence : float\n",
    "        The confidence level (default is 90%).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (lower_bound, upper_bound)\n",
    "        The confidence interval for the estimated probability.\n",
    "    \"\"\"\n",
    "    delta = 1 - confidence  # Confidence level (e.g., 0.10 for 90% interval)\n",
    "    if n_samples == 0:\n",
    "        return (0, 1)  # If no samples found, return full range [0,1]\n",
    "    \n",
    "    epsilon = np.sqrt(np.log(2 / delta) / (2 * n_samples))  # Compute Hoeffding bound\n",
    "\n",
    "    # Compute confidence interval\n",
    "    lower_bound = max(0, estimated_prob - epsilon)  # Ensure non-negative\n",
    "    upper_bound = min(1, estimated_prob + epsilon)  # Ensure probability stays ≤ 1\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example Usage\n",
    "# Assume sms_no_spam is a list of tuples [(text1, label1), (text2, label2), ...]\n",
    "estimated_prob, n_samples = estimate_spam_probability_for_free_twice(sms_no_spam)\n",
    "\n",
    "# Compute confidence interval\n",
    "confidence_interval = compute_hoeffding_confidence_interval(estimated_prob, n_samples)\n",
    "\n",
    "# Print results\n",
    "print(f\"P(Y = 1 | 'free' appears twice) ≈ {estimated_prob:.4f}\")\n",
    "print(f\"Number of relevant SMS samples: {n_samples}\")\n",
    "print(f\"90% Confidence Interval: {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 5 markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/flights.csv\"  # Ensure this path is correct\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant information\n",
    "number_of_cities = df['origin'].nunique()  # Count unique cities in the dataset\n",
    "number_of_userCodes = df['user_id'].nunique()  # Count unique users (travelers)\n",
    "number_of_observations = len(df)  # Total number of flights (observations)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of cities: {number_of_cities}\")\n",
    "print(f\"Number of unique users: {number_of_userCodes}\")\n",
    "print(f\"Number of flight observations: {number_of_observations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Enumerate cities in alphabetical order\n",
    "unique_cities = sorted(df['origin'].unique())  # Get unique city names in sorted order\n",
    "city_to_index = {city: idx for idx, city in enumerate(unique_cities)}\n",
    "\n",
    "# Step 2: Map cities to indices in the dataset\n",
    "df['origin_index'] = df['origin'].map(city_to_index)\n",
    "df['destination_index'] = df['destination'].map(city_to_index)\n",
    "\n",
    "# Step 3: Create transition frequency dictionary\n",
    "transition_pairs = list(zip(df['origin_index'], df['destination_index']))\n",
    "transition_counts = makeFreqDict(transition_pairs)  # Using the provided function\n",
    "\n",
    "# Step 4: Build the transition matrix\n",
    "num_cities = len(unique_cities)\n",
    "transition_matrix = np.zeros((num_cities, num_cities))\n",
    "\n",
    "# Fill the matrix with frequency counts\n",
    "for (from_city, to_city), count in transition_counts.items():\n",
    "    transition_matrix[from_city, to_city] = count\n",
    "\n",
    "# Step 5: Normalize the transition matrix (convert counts to probabilities)\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Display the transition matrix\n",
    "import ace_tools as tools\n",
    "import pandas as pd\n",
    "\n",
    "transition_df = pd.DataFrame(transition_matrix, index=unique_cities, columns=unique_cities)\n",
    "tools.display_dataframe_to_user(name=\"Transition Matrix\", dataframe=transition_df)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Markov chain transition matrix computed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_stationary_distribution(transition_matrix):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution of a Markov chain given its transition matrix.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    transition_matrix : numpy array (n_cities x n_cities)\n",
    "        The Markov transition matrix.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy array\n",
    "        The stationary distribution vector.\n",
    "    \"\"\"\n",
    "    # Compute the left eigenvector corresponding to eigenvalue 1\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "\n",
    "    # Find the eigenvector corresponding to eigenvalue closest to 1\n",
    "    stationary_vector = np.real(eigenvectors[:, np.isclose(eigenvalues, 1)].flatten())\n",
    "\n",
    "    # Normalize the vector to sum to 1 (probability distribution)\n",
    "    stationary_distribution = stationary_vector / stationary_vector.sum()\n",
    "\n",
    "    return stationary_distribution\n",
    "\n",
    "# Compute stationary distribution using our transition matrix\n",
    "stationary_distribution = compute_stationary_distribution(transition_matrix)\n",
    "\n",
    "# Display the result\n",
    "import ace_tools as tools\n",
    "import pandas as pd\n",
    "\n",
    "stationary_df = pd.DataFrame(stationary_distribution, index=unique_cities, columns=[\"Stationary Probability\"])\n",
    "tools.display_dataframe_to_user(name=\"Stationary Distribution\", dataframe=stationary_df)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Stationary distribution computed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_return_probability(transition_matrix, start_city, steps, city_to_index):\n",
    "    \"\"\"\n",
    "    Computes the probability of returning to a city after a given number of steps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    transition_matrix : numpy array\n",
    "        The Markov chain transition matrix.\n",
    "    start_city : str\n",
    "        The city name from which we start.\n",
    "    steps : int\n",
    "        The number of steps to take in the Markov process.\n",
    "    city_to_index : dict\n",
    "        A dictionary mapping city names to indices.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The probability of returning to the start city after 'steps' transitions.\n",
    "    \"\"\"\n",
    "    # Compute P^steps (transition matrix raised to power 'steps')\n",
    "    P_n = np.linalg.matrix_power(transition_matrix, steps)\n",
    "\n",
    "    # Get the index of the starting city\n",
    "    city_index = city_to_index[start_city]\n",
    "\n",
    "    # Probability of returning to the same city after 'steps' steps\n",
    "    return_probability = P_n[city_index, city_index]\n",
    "\n",
    "    return return_probability\n",
    "\n",
    "# Define start city and number of steps\n",
    "start_city = \"Aracaju (SE)\"\n",
    "steps = 3\n",
    "\n",
    "# Compute return probability\n",
    "return_probability = compute_return_probability(transition_matrix, start_city, steps, city_to_index)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Probability of returning to '{start_city}' after {steps} steps: {return_probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 6 blackbox testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes precision for class 1.\n",
    "\n",
    "    Parameters:\n",
    "    y_true : list or numpy array\n",
    "        True labels (0 = non-spam, 1 = spam).\n",
    "    y_pred : list or numpy array\n",
    "        Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    precision : float\n",
    "        Precision for class 1.\n",
    "    n_positive_preds : int\n",
    "        Number of predicted positive samples (TP + FP).\n",
    "    \"\"\"\n",
    "    TP = sum((y_pred == 1) & (y_true == 1))\n",
    "    FP = sum((y_pred == 1) & (y_true == 0))\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    return precision, (TP + FP)\n",
    "\n",
    "def compute_hoeffding_bound(n_samples, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Computes the Hoeffding bound for a given number of samples.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        Number of samples used in the calculation.\n",
    "    confidence : float\n",
    "        Confidence level.\n",
    "\n",
    "    Returns:\n",
    "    l : float\n",
    "        Hoeffding confidence bound.\n",
    "    \"\"\"\n",
    "    delta = 1 - confidence\n",
    "    l = np.sqrt(np.log(2 / delta) / (2 * n_samples)) if n_samples > 0 else 0\n",
    "    return l\n",
    "\n",
    "# Example Usage\n",
    "y_true = np.array([...])  # Replace with actual test labels\n",
    "y_pred = np.array([...])  # Replace with actual predicted labels\n",
    "\n",
    "precision, n_positive_preds = compute_precision(y_true, y_pred)\n",
    "l = compute_hoeffding_bound(n_positive_preds)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({max(0, precision - l):.4f}, {min(1, precision + l):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes recall for class 1.\n",
    "\n",
    "    Parameters:\n",
    "    y_true : list or numpy array\n",
    "        True labels (0 = non-spam, 1 = spam).\n",
    "    y_pred : list or numpy array\n",
    "        Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    recall : float\n",
    "        Recall for class 1.\n",
    "    n_actual_positives : int\n",
    "        Number of actual positive samples (TP + FN).\n",
    "    \"\"\"\n",
    "    TP = sum((y_pred == 1) & (y_true == 1))\n",
    "    FN = sum((y_pred == 0) & (y_true == 1))\n",
    "    \n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    return recall, (TP + FN)\n",
    "\n",
    "# Example Usage\n",
    "recall, n_actual_positives = compute_recall(y_true, y_pred)\n",
    "l = compute_hoeffding_bound(n_actual_positives)\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({max(0, recall - l):.4f}, {min(1, recall + l):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, total_samples\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m accuracy, n_samples \u001b[38;5;241m=\u001b[39m compute_accuracy(\u001b[43my_true\u001b[49m, y_pred)\n\u001b[0;32m     25\u001b[0m l \u001b[38;5;241m=\u001b[39m compute_hoeffding_bound(n_samples)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    y_true : list or numpy array\n",
    "        True labels.\n",
    "    y_pred : list or numpy array\n",
    "        Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    accuracy : float\n",
    "        Accuracy of the model.\n",
    "    n_samples : int\n",
    "        Number of total samples.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(y_true == y_pred)\n",
    "    total_samples = len(y_true)\n",
    "    \n",
    "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0\n",
    "    return accuracy, total_samples\n",
    "\n",
    "# Example Usage\n",
    "accuracy, n_samples = compute_accuracy(y_true, y_pred)\n",
    "l = compute_hoeffding_bound(n_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({max(0, accuracy - l):.4f}, {min(1, accuracy + l):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_dimension_effect(n_samples, vc_dim, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Computes the theoretical sample size required to reduce the Hoeffding bound.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples : int\n",
    "        The available sample size.\n",
    "    vc_dim : int\n",
    "        The VC-dimension of the classifier.\n",
    "    confidence : float\n",
    "        Confidence level (default 95%).\n",
    "\n",
    "    Returns:\n",
    "    required_samples : int\n",
    "        The estimated number of samples needed for a reduced confidence interval.\n",
    "    \"\"\"\n",
    "    delta = 1 - confidence\n",
    "    epsilon = np.sqrt(np.log(2 / delta) / (2 * n_samples))\n",
    "    \n",
    "    # Theoretical number of samples needed based on VC-dimension\n",
    "    required_samples = (1 / epsilon**2) * (vc_dim * np.log(2 * n_samples / vc_dim) + np.log(2 / delta))\n",
    "    \n",
    "    return int(required_samples)\n",
    "\n",
    "# Example Usage\n",
    "vc_dim = 3\n",
    "required_samples = vc_dimension_effect(n_samples, vc_dim)\n",
    "\n",
    "print(f\"Required samples for VC-dimension {vc_dim} to reduce interval: {required_samples}\")\n",
    "print(f\"Using all data would likely result in a smaller confidence interval for accuracy.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
